#!/bin/bash
#SBATCH --job-name=kurbanski_cnn_pytorch
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --ntasks-per-node=1
#SBATCH --time=3:00:00
#SBATCH --mem=60000M
#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1

module purge
module load 2019
module load Anaconda3/2018.12
. /sw/arch/Debian9/EB_production/2019/software/Anaconda3/2018.12/etc/profile.d/conda.sh

conda activate dl

mkdir $TMPDIR/results_kurbanski

#PALINDROME_LENGTH=($(seq 5 1 15))
PALINDROME_LENGTH=($(seq 5 1 5))
for LENGTH in "${PALINDROME_LENGTH[@]}"
do
	printf "$LENGTH,"
	python train.py --input_length $LENGTH --train_log "${TMPDIR}/results_kurbanski/length_${LENGTH}.log"
	echo ""
done

cp $TMPDIR/results_kurbanski/*.log ./results/
