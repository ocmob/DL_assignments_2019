#!/bin/bash
#SBATCH --job-name=kurbanski_rnn_palindromes
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --ntasks-per-node=1
#SBATCH --time=6:00:00
#SBATCH --mem=60000M
#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1

module purge
module load 2019
module load Anaconda3/2018.12
. /sw/arch/Debian9/EB_production/2019/software/Anaconda3/2018.12/etc/profile.d/conda.sh

conda activate dl

mkdir $TMPDIR/results_kurbanski

#PALINDROME_LENGTH=($(seq 10 1 15))
PALINDROME_LENGTH=(3)
for LENGTH in "${PALINDROME_LENGTH[@]}"
do
	echo "RNN LINEAR"
	printf "$LENGTH,"
	python train.py --model_type RNN --linear --input_length $LENGTH --train_log "${TMPDIR}/results_kurbanski/RNN_linear_length_${LENGTH}.log"
	echo ""

	echo "RNN"
	printf "$LENGTH,"
	python train.py --model_type RNN --input_length $LENGTH --train_log "${TMPDIR}/results_kurbanski/RNN_length_${LENGTH}.log"
	echo ""
done

PALINDROME_LENGTH=(20 30 35 40)
PALINDROME_LENGTH=(3)
for LENGTH in "${PALINDROME_LENGTH[@]}"
do
	echo "LSTM LINEAR"
	printf "$LENGTH,"
	python train.py --model_type LSTM --linear --input_length $LENGTH --train_log "${TMPDIR}/results_kurbanski/LSTM_linear_length_${LENGTH}.log"
	echo ""

	echo "LSTM"
	printf "$LENGTH,"
	python train.py --model_type LSTM --input_length $LENGTH --train_log "${TMPDIR}/results_kurbanski/LSTM_length_${LENGTH}.log"
	echo ""
done

cp $TMPDIR/results_kurbanski/*.log ./results/
