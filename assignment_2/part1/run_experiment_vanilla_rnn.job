#!/bin/bash
#SBATCH --job-name=kurbanski_cnn_pytorch
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --ntasks-per-node=1
#SBATCH --time=3:00:00
#SBATCH --mem=60000M
#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1

module purge
module load 2019
module load Anaconda3/2018.12
. /sw/arch/Debian9/EB_production/2019/software/Anaconda3/2018.12/etc/profile.d/conda.sh
conda activate dl

cp -r /home/lgpu0296/DL_assignments_2019/assignment_1/code/cifar10 ${TMPDIR}/cifar10

#PALINDROME_LENGTH=($(seq 5 1 20))
PALINDROME_LENGTH=($(seq 5 1 5))
for LENGTH in "${PALINDROME_LENGTH[@]}"
do
	printf "$PALINDROME_LENGTH,"
	python3 train.py --input_length = $LENGTH
	echo ""
done
